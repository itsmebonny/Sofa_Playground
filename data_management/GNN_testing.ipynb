{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playground for GNN data processing\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch as th\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract filenames from npy_GNN folder\n",
    "\n",
    "def get_filenames(directory):\n",
    "    filenames = []\n",
    "    for file in os.listdir(f\"../npy_GNN/{directory}\"):\n",
    "        if file[-4:] == \".npy\":\n",
    "            filenames.append(file)\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "names = get_filenames(\"2024-05-15_11:57:51_dynamic\")\n",
    "print(names)\n",
    "\n",
    "# create a second list with the same filenames but without everything after the first underscore\n",
    "\n",
    "def get_filenames_no_time(directory):\n",
    "    filenames = []\n",
    "    for file in os.listdir(f\"../npy_GNN/{directory}\"):\n",
    "        if file[-4:] == \".npy\":\n",
    "            filenames.append(file)\n",
    "    filenames.sort()\n",
    "    for i in range(len(filenames)):\n",
    "        filenames[i] = filenames[i].split(\"_\")[0] + \".npy\"\n",
    "    return filenames\n",
    "\n",
    "names_no_time = get_filenames_no_time(\"2024-05-15_11:57:51_dynamic\")\n",
    "types = len(set(names_no_time))\n",
    "\n",
    "samples = len(names) // types\n",
    "print(types, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph \n",
    "#load displacement data \n",
    "high_res_displacement = np.load(f\"../npy_GNN/2024-05-15_11:57:51_dynamic/{names[samples*3]}\")\n",
    "low_res_displacement = np.load(f\"../npy_GNN/2024-05-15_11:57:51_dynamic/{names[0]}\")\n",
    "\n",
    "high_res_velocity = np.load(f\"../npy_GNN/2024-05-15_11:57:51_dynamic/{names[samples*4]}\")\n",
    "low_res_velocity = np.load(f\"../npy_GNN/2024-05-15_11:57:51_dynamic/{names[samples*5]}\")\n",
    "\n",
    "#node features are just high res displacement and velocity horizontally stacked\n",
    "node_features = np.hstack((high_res_displacement, high_res_velocity))\n",
    "print(node_features.shape)\n",
    "edge_index = np.load(f\"../npy_GNN/2024-05-15_11:57:51_dynamic/{names[samples*2]}\")[:, :2].T\n",
    "edge_attr = np.load(f\"../npy_GNN/2024-05-15_11:57:51_dynamic/{names[samples*2]}\")[:, 2]\n",
    "\n",
    "print(edge_index)\n",
    "print(edge_attr.shape)\n",
    "\n",
    "y = high_res_displacement - low_res_displacement\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "data = Data(x=th.tensor(node_features, dtype=th.float32), edge_index=th.tensor(edge_index, dtype=th.long), edge_attr=th.tensor(edge_attr, dtype=th.float32), y=th.tensor(y, dtype=th.float32))\n",
    "\n",
    "# create a function to transform the data into a list of Data objects\n",
    "\n",
    "def create_data_list(directory):\n",
    "    names = get_filenames(directory)\n",
    "    names_no_time = get_filenames_no_time(directory)\n",
    "    types = len(set(names_no_time))\n",
    "    samples = len(names) // types\n",
    "    data_list = []\n",
    "    for i in range(samples):\n",
    "        high_res_displacement = np.load(f\"../npy_GNN/{directory}/{names[samples*3+i]}\")\n",
    "        low_res_displacement = np.load(f\"../npy_GNN/{directory}/{names[i]}\")\n",
    "        high_res_velocity = np.load(f\"../npy_GNN/{directory}/{names[samples*4+i]}\")\n",
    "        node_features = np.hstack((high_res_displacement, high_res_velocity))\n",
    "        edge_index = np.load(f\"../npy_GNN/{directory}/{names[samples*2+i]}\")[:, :2].T\n",
    "        edge_attr = np.load(f\"../npy_GNN/{directory}/{names[samples*2+i]}\")[:, 2]\n",
    "        y = high_res_displacement - low_res_displacement\n",
    "        data = Data(x=th.tensor(node_features, dtype=th.float32), edge_index=th.tensor(edge_index, dtype=th.long), edge_attr=th.tensor(edge_attr, dtype=th.float32), y=th.tensor(y, dtype=th.float32))\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "data_list = create_data_list(\"2024-05-15_16:08:01_dynamic\")\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a GNN model that takes as input a Data object and outputs a prediction of shape (250, 3)\n",
    "from torch.functional import F\n",
    "\n",
    "class Net(th.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(6, 16)\n",
    "        self.conv_mid = GCNConv(16, 16)\n",
    "        self.conv2 = GCNConv(16, 3)\n",
    "        self.repeat = 10 \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        for i in range(self.repeat):\n",
    "            x = self.conv_mid(x, edge_index, edge_attr)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# train the model\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "data_list = [data.to(device) for data in data_list]\n",
    "\n",
    "\n",
    "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.mse_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data in loader:\n",
    "    out = model(data)\n",
    "    print(out.shape)\n",
    "    print(data.y.shape)\n",
    "    print(F.mse_loss(out, data.y).item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
